# -*- coding: utf-8 -*-
"""190376N_label1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DxEA_IJ80SNZTvtjYz4OSPEl6Lu6wwTa
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
from sklearn.decomposition import PCA

# Load the data
train_data = pd.read_csv('train.csv')
valid_data = pd.read_csv('valid.csv')
test_data = pd.read_csv('test.csv')

# Split data into features (X) and target labels (y)
X_train = train_data.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_label1_train = train_data['label_1']

X_valid = valid_data.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_valid_label1 = valid_data['label_1']

X_test = test_data.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)

# Initialize models
model_label1 = SVC(random_state=42, kernel='linear', gamma='auto')

# Train models
model_label1.fit(X_train, y_label1_train)

# Predictions
pred_label1 = model_label1.predict(X_valid)

pred_label1_test = model_label1.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_valid_label1, pred_label1)
precision = precision_score(y_valid_label1, pred_label1, average='weighted', zero_division=1)
recall = recall_score(y_valid_label1, pred_label1, average='weighted')

print(f"Metrics for label 1 before feature engineering:")
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print("\n")

output_label1 = pd.DataFrame(index=range(750))
output_label1['Predicted labels before feature engineering'] = np.nan

# Fill the available rows with predicted values
output_label1.loc[:len(pred_label1_test)-1, 'Predicted labels before feature engineering'] = pred_label1_test

"""Applying Feature Engineering techniques"""

sc = RobustScaler()

X_train_scaled = sc.fit_transform(X_train)
X_valid_scaled = sc.transform(X_valid)
X_test_scaled = sc.transform(X_test)

# Calculate the variance threshold
desired_variance = 0.95  # Set the desired explained variance
pca = PCA(n_components=desired_variance, svd_solver='full')
X_train_pca = pca.fit_transform(X_train_scaled)
X_valid_pca =pca.transform(X_valid_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Get the number of components selected based on the variance threshold
n_components = pca.n_components_

model_label1.fit(X_train_pca,y_label1_train)
pred_label1= model_label1.predict(X_valid_pca)
pred_label1_test = model_label1.predict(X_test_pca)
# Calculate accuracy
accuracy = accuracy_score(y_valid_label1, pred_label1)
precision = precision_score(y_valid_label1, pred_label1, average='weighted', zero_division=1)
recall = recall_score(y_valid_label1, pred_label1, average='weighted')

print(f"Metrics for label 1 after feature engineering:")
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print("\n")


output_label1['Predicted labels after feature engineering']=pred_label1_test
output_label1['No of new features']=n_components

# Add PCA components to the DataFrame
for i in range(n_components):
    component_name = f'new_feature_{i+1}'
    output_label1[component_name] = X_test_pca[:, i]

# Save the output DataFrame to a CSV file
output_label1.to_csv('190376N_lable_1.csv', index=False)